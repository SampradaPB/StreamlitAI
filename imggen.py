import streamlit as st
import requests
import io
from PIL import Image

# â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="AI Image Generator",
    page_icon="ğŸ¨",
    layout="centered"
)

# â”€â”€ Freely accessible models (no license gate) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS = {
    "âœ… Dreamlike Photoreal 2.0 (Best Quality)": "dreamlike-art/dreamlike-photoreal-2.0",
    "âœ… Stable Diffusion 2.1 (Fast & Reliable)": "stabilityai/stable-diffusion-2-1",
    "âœ… Openjourney v4 (Artistic / MidJourney style)": "prompthero/openjourney-v4",
    "âœ… Realistic Vision v3 (Photorealistic)":   "SG161222/Realistic_Vision_V3.0_VAE",
}

BASE_URL = "https://router.huggingface.co/hf-inference/models"


# â”€â”€ Query Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def query(hf_token: str, model_id: str, payload: dict):
    api_url = f"{BASE_URL}/{model_id}"
    headers = {"Authorization": f"Bearer {hf_token}"}

    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=120)

        if response.status_code == 401:
            st.error("âŒ Invalid token â€” please double-check your Hugging Face API token.")
            return None
        elif response.status_code == 403:
            st.error(
                "âŒ Access denied for this model. Try a different model from the dropdown, "
                "or accept the license at huggingface.co/models"
            )
            return None
        elif response.status_code == 503:
            st.warning("â³ Model is loading on HF servers. Wait 20â€“30 sec and try again.")
            return None
        elif response.status_code != 200:
            st.error(f"âŒ API Error {response.status_code}: {response.text[:300]}")
            return None

        content_type = response.headers.get("Content-Type", "")
        if "image" not in content_type:
            st.error(f"âŒ Unexpected response (not an image): {response.text[:300]}")
            return None

        return response.content

    except requests.exceptions.Timeout:
        st.error("âŒ Request timed out â€” model may be busy. Please try again.")
        return None
    except requests.exceptions.ConnectionError:
        st.error("âŒ Connection error. Please check your internet.")
        return None


# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ğŸ”‘ API Configuration")
    st.markdown(
        "Get a **free token** at "
        "[huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)"
    )

    hf_token = st.text_input(
        "Hugging Face Token",
        type="password",
        placeholder="hf_xxxxxxxxxxxxxxxxxxxx",
        help="Used only for this request. Never stored or logged."
    )

    if hf_token:
        st.success("âœ… Token entered")
    else:
        st.info("â„¹ï¸ Enter your token to enable generation")

    st.divider()

    selected_label = st.selectbox("ğŸ¤– Choose Model", list(MODELS.keys()))
    selected_model = MODELS[selected_label]
    st.caption(f"`{selected_model}`")

    st.divider()
    st.caption("ğŸ”’ Your token is never stored â€” it goes directly to Hugging Face per request.")


# â”€â”€ Main UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ¨ AI Image Generator")
st.caption("Powered by Hugging Face Inference API â€” no license required models")
st.divider()

prompt = st.text_area(
    "âœï¸ Describe the image you want:",
    placeholder="A futuristic cyberpunk city at night, neon lights, rain-soaked streets, photorealistic",
    height=100
)

negative_prompt = st.text_input(
    "ğŸš« Negative prompt (what to avoid):",
    value="blurry, low quality, distorted, watermark, ugly, duplicate, deformed",
)

col1, col2 = st.columns(2)
with col1:
    steps = st.slider("Inference Steps", 10, 50, 30, 5,
                      help="More steps = better quality but slower.")
with col2:
    guidance = st.slider("Guidance Scale", 1.0, 15.0, 7.5, 0.5,
                         help="Higher = image follows prompt more strictly.")

st.divider()

# â”€â”€ Generate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("âœ¨ Generate Image", type="primary", use_container_width=True):

    if not hf_token.strip():
        st.warning("âš ï¸ Please enter your Hugging Face API token in the sidebar.")
        st.stop()

    if not prompt.strip():
        st.warning("âš ï¸ Please enter a prompt.")
        st.stop()

    with st.spinner(f"ğŸ–¼ï¸ Generating with `{selected_model}`... (20â€“40 sec)"):
        payload = {
            "inputs": prompt.strip(),
            "parameters": {
                "negative_prompt": negative_prompt.strip(),
                "num_inference_steps": steps,
                "guidance_scale": guidance,
            }
        }
        image_bytes = query(hf_token.strip(), selected_model, payload)

    if image_bytes:
        try:
            image = Image.open(io.BytesIO(image_bytes))
            st.success("âœ… Image generated successfully!")
            st.image(image, caption=f'"{prompt}"', use_container_width=True)

            buf = io.BytesIO()
            image.save(buf, format="PNG")
            buf.seek(0)

            st.download_button(
                label="â¬‡ï¸ Download Image (PNG)",
                data=buf.getvalue(),
                file_name="generated_image.png",
                mime="image/png",
                use_container_width=True
            )
        except Exception as e:
            st.error(f"âŒ Could not render image: {str(e)}")
